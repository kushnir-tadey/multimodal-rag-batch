# ğŸ§  Multimodal AI News RAG

A production-ready **Retrieval-Augmented Generation (RAG)** system that aggregates AI news, processes it with smart recursive chunking, and enables users to search across both text and images using natural language.

## âœ¨ Key Features

* **ğŸ” Multimodal Search:** Retrieves both relevant text paragraphs and associated images for a query.
* **ğŸ§  Recursive Chunking:** Uses advanced text splitting (NLTK/LangChain) to preserve semantic context.
* **ğŸ“Š Analytics Dashboard:**
    * **N-Gram Analysis:** Visualizes top keywords, bi-grams, and tri-grams.
    * **Health Metrics:** Monitors chunk sizes and distribution.
* **âš¡ Automated Pipeline:** Single-command processing from raw scraping to vector indexing.
* **ğŸ¤– GPT-4o-mini Integration:** Generates grounded, accurate answers citing specific news sources.

---

## ğŸš€ Quick Start (Docker) ğŸ³

The easiest way to run the app. No Python installation required.

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/kushnir-tadey/multimodal-rag-batch.git](https://github.com/kushnir-tadey/multimodal-rag-batch.git)
    cd multimodal-rag-batch
    ```

2.  **Add your API Key:**
    Create a `.env` file in the root folder:
    ```ini
    OPENAI_API_KEY="sk-..."
    ```

3.  **Run:**
    ```bash
    docker compose up --build
    ```
    *The app will automatically index the data and launch.*

4.  **Open:** [http://localhost:8501](http://localhost:8501)

## ğŸ—ï¸ Architecture

1.  **Data Collection (Scraper):**
    * Fetches the latest AI news articles and associated images.
    * Saves raw data to `data/raw/` for auditing.

2.  **Indexing Engine:**
    * **Preprocessing:** Cleans raw HTML text and normalizes content.
    * **Recursive Chunking:** Uses `RecursiveCharacterTextSplitter` to break text into semantic units (preserving paragraphs and sentences) rather than arbitrary character counts.
    * **Embedding:** Converts text and images into vector embeddings using `SentenceTransformers`.
    * **Storage:** Saves vectors into a local **FAISS** index for millisecond-latency search.

3.  **RAG Engine:**
    * **Retrieval:** Finds the top-k most relevant chunks based on vector similarity to the user's query.
    * **Generation:** Feeds the retrieved context to **GPT-4o-mini**, which generates a grounded, accurate answer citing specific sources.

4.  **User Interface:**
    * A Streamlit-based web app for interactive search.
    * Dedicated Analytics Dashboard for system monitoring.

---

## ğŸ“Š Analytics & Evaluation

The system includes a production-grade **Analytics Dashboard** to monitor data health and content trends.

### 1. Content Analysis (NLP)
* **N-Gram Extraction:** visualizes top **Bi-grams** (2-word pairs) and **Tri-grams** (3-word phrases) to understand trending topics.
* **Lemmatization:** Uses NLTK to normalize words for accurate frequency counts.

### 2. Structural Health Metrics
* **Words per Chunk:** Monitors the distribution of chunk sizes.
* **Chunks per Article:** Visualizes the depth of indexed content (short news vs. long-form analysis).

---

## ğŸ“‚ Project Structure

```text
multimodal-rag-batch/
â”œâ”€â”€ data/                   # Storage for data artifacts
â”‚   â”œâ”€â”€ faiss_index/        # Vector database files
â”‚   â”œâ”€â”€ images/             # Scraped images
â”‚   â”œâ”€â”€ processed/          # Cleaned JSON data for Analytics
â”‚   â””â”€â”€ raw/                # Raw scraped data
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ indexing/           # ETL & Indexing logic
â”‚   â”‚   â”œâ”€â”€ chunker.py      # Recursive text splitting
â”‚   â”‚   â””â”€â”€ indexer.py      # Main indexing pipeline
â”‚   â”œâ”€â”€ rag/                # RAG Core Modules
â”‚   â”‚   â”œâ”€â”€ generator.py    # OpenAI generation logic
â”‚   â”‚   â””â”€â”€ retriever.py    # FAISS search logic
â”‚   â”œâ”€â”€ scraping/           # Data collection
â”‚   â”‚   â””â”€â”€ batch_scraper.py
â”‚   â”œâ”€â”€ ui/                 # Frontend application
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â””â”€â”€ Analytics.py # Dashboard
â”‚   â”‚   â””â”€â”€ app.py          # Main entry point
â”‚   â””â”€â”€ config.py           # Global settings
â”œâ”€â”€ venv/                   # Virtual Environment
â”œâ”€â”€ .env                    # API Keys (Git-ignored)
â”œâ”€â”€ .gitignore              # Git ignore rules
â””â”€â”€ requirements.txt        # Python dependencies

## ğŸ› ï¸ Technologies Used

* **Core Language:** Python 3.10+
* **LLM & AI:** OpenAI GPT-4o-mini
* **Vector Database:** FAISS (Facebook AI Similarity Search)
* **Embeddings:** SentenceTransformers (HuggingFace `all-MiniLM-L6-v2`)
* **Web Framework:** Streamlit
* **Data Processing:**
    * **LangChain:** Recursive Text Splitting
    * **NLTK:** Stopword removal & Lemmatization
    * **Scikit-Learn:** N-gram analysis (Bi-grams/Tri-grams)
    * **Pandas:** Data manipulation
    * **BeautifulSoup4:** HTML parsing & scraping
* **Containerization:** Docker & Docker Compose